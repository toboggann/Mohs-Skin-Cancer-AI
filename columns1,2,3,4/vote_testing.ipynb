{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "175baba7-cdce-482e-8fa4-495a6a0ff036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use full Excel sheet\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "Cat = pd.read_excel(r'../De-Identified Mohs Full Data.xlsx',sheet_name='Identified Data',header=0) # Only Size at Greatest Dimension column\n",
    "sample_size = len(Cat)\n",
    "\n",
    "#txt_string = r'at_GPT_data/at_column_data.txt' # No prompt change\n",
    "#txt_string = r'at_GPT_data/at_column_data_change_4.txt' # Prompt change 3\n",
    "\n",
    "#txt_string = r'GPT_data/location_data(1).txt'\n",
    "#txt_string = r'GPT_data/aggressive_tumor_data(1).txt'\n",
    "#txt_string = r'GPT_data/dfsp_data(1).txt'\n",
    "#txt_string = r'GPT_data/recurrent_tumor_data(1).txt'\n",
    "\n",
    "#txt_string = r'GPT_data/cf_data(1).txt'\n",
    "#txt_string = r'GPT_data/ae_data(3).txt'\n",
    "#txt_string = r'GPT_data/ms_data(1).txt'\n",
    "#txt_string = r'GPT_data/ent_data(1).txt'\n",
    "\n",
    "txt_string = r'GPT_data/tumor_size_data(1).txt'\n",
    "\n",
    "#ground_truth_string = 'Location - Nose, Eyelid, Nail, Lip, Genitalia, or Acral (L)'\n",
    "#ground_truth_string = 'Aggressive Tumor Pathology Type (AT)'\n",
    "#ground_truth_string = 'DFSP (D)'\n",
    "#ground_truth_string = 'Recurrent Tumor (R)'\n",
    "\n",
    "#ground_truth_string = 'Additional C&F'\n",
    "#ground_truth_string = 'Additional Excision'\n",
    "#ground_truth_string = 'Multiple Sites'\n",
    "#ground_truth_string = 'Coordinated repair with ENT/oculoplastics (C)'\n",
    "\n",
    "ground_truth_string = 'Size at Greatest Dimension (S) ***Be  sure this is from the note and not the Mohs episode!'\n",
    "\n",
    "only_A_flag = False # Only check Addendum if True\n",
    "# Array of indexes containing patients with notes that have problems\n",
    "skip_patients_array = [7,8,22,23,32,34,38,39,49,50,52,55,62,66,73,80,88,89,101,102,107,110,121,123,131,133,135,\n",
    "                       136,137,140,150,155,157,164,170,184,187,193,200,206,210,214,227,228,229,234,252,261,265,279,287,292,293]\n",
    "skip_patients = True # Set to True to skip bad patient notes, False to keep them in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7021d5c5-1606-477c-b774-82210669621e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of 'Y' in Ground Truth: 0\n",
      "# of 'N' in Ground Truth: 0\n",
      "# of NaN values in Ground Truth: 93\n",
      "Ground Truth:\n",
      "[0.8, 0.6, 0.3, 6.5, 3.5, 0.4, 0.3, -1, -1, 1.5, 1.2, 1.3, -1, 0.3, 0.7, 0.5, 0.4, 0.4, -1, 0.5, 0.8, 0.4, 1.0, 0.3, -1, 1.1, 0.4, 1.7, 0.5, 1.8, -1, 1.0, 0.7, 0.4, 0.6, 0.2, -1, 0.8, 0.7, 0.8, 0.9, 0.5, -1, 0.8, 1.4, 0.7, -1, 1.3, 1.5, 0.4, 0.7, -1, 1.5, 0.5, 0.5, 0.9, -1, -1, -1, -1, 0.9, -1, 4.2, -1, -1, 0.7, 0.7, -1, 0.6, 0.4, 0.2, -1, 0.7, 0.6, 1.2, 1.0, -1, 1.8, -1, 0.7, 0.4, 0.4, -1, 0.4, -1, 0.6, -1, -1, 0.6, 0.1, 0.7, 0.4, 0.9, -1, 0.4, -1, 0.6, 0.5, 1.2, 0.5, 1.0, 0.6, 0.5, 0.5, -1, 2.5, 1.1, 0.4, -1, 0.5, 0.6, 0.4, 0.4, -1, 0.7, 1.0, 0.3, -1, -1, 1.2, -1, -1, -1, 0.4, 0.6, -1, 2.0, -1, 0.9, -1, -1, 1.7, 1.1, 0.4, 0.5, 0.8, 0.8, 1.6, -1, -1, 0.2, 1.5, -1, -1, 1.2, 0.4, 0.5, 0.3, 1.3, 0.8, 0.8, -1, -1, 0.6, -1, 0.5, 0.5, 0.4, -1, -1, 0.1, 2.2, -1, 2.5, 0.3, 0.4, -1, -1, 0.6, 0.8, 0.3, 0.8, -1, 0.8, -1, 0.4, 0.4, -1, 0.5, 0.5, -1, -1, -1, 2.5, 1.5, -1, -1, 1.5, 0.5, 2.0, -1, -1, 0.6, 0.4, 0.5, 0.6, -1, 1.0, -1, 0.6, 0.8, -1, -1, 0.5, -1, 0.6, 0.2, 1.0, 1.1, 1.7, 0.4, -1, 0.5, -1, 0.9, 0.4, -1, 1.2, 0.5, 0.2, -1, 1.2, -1, -1, -1, 0.8, -1, 0.6, 0.5, 0.5, -1, 0.5, 0.4, -1, 1.0, 0.6, 0.4, 0.2, -1, 0.6, 0.3, 0.4, 0.6, 0.8, -1, -1, 0.9, 1.4, 0.4, -1, -1, 0.3, 0.6, 0.8, 0.2, -1, 0.4, -1, -1, -1, 0.9, 0.2, 1.4, 0.5, -1, 0.3, 0.4, 0.7, 0.6, 0.5, 0.5, -1, 2.2, -1, 1.5, 0.9, 0.5, 0.6, 0.6, 1.6, 0.4, -1, 0.5, -1, 0.7, -1, -1, 0.4, 1.3, 0.6, 1.3, -1, 0.6, 0.4]\n",
      "PE Unfiltered Array:\n",
      "['[\"0.8 x 0.8 cm\", \"0.4 x 0.5 cm\"]', '[\"0.6cm x 0.4cm\"]', '[\"3mm x 3mm\"]', '[\"6.5 x 5.0cm\"]', '[\"0.6 x 0.8cm\", \"1.2 x 1.6cm\", \"1 x 1cm\", \"', '[\"0.4 x 0.3cm\"]', '[\"0.3 x 0.3\"]', '[\"0.5cm\", \"8mm\", \"8mm x 5mm\"]', '[\"1 x 0.7 cm\", \"1.5 x 1\", \"1 x 1.5 cm\"]', '[\"1.5 cm x 1 cm\", \"8 mm x 5 mm\"]', '[\"1 x 1.2cm\"]', '[]', '[]', '[\"3mm x 3mm\"]', '[\"7mm\"]', '[\"0.5cm\"]', '[\"0.4cm\"]', '[\"0.4cm\"]', '[\"1cm\"]', '[\"0.5cm\"]', '[\"3mm x 5mm\", \"3mm x 8mm\"]', '[\"4mm\"]', '[\"1.0 x 0.8cm\"]', '[\"0.4cm\", \"0.3cm\"]', '[\"1.0cm\", \"1.5cm\"]', '[\"1 cm x 1.1 cm\", \"0.7 cm x 0.7 cm\"]', '[\"4mm\"]', '[\"1.1 x 1.7\"]', '[\"0.5 x 0.4cm\"]', '[\"1.8cm\", \"1.0cm\"]', '[]', '[\"1cm\"]', '[\"0.7cm x 0.5cm\", \"0.6cm x 0.5cm\", \"3.5cm x', '[]', '[]', '[\"2mm\"]', '[]', '[\"0.8 x 0.8cm\"]', '[]', '[]', '[\"0.7 x 0.9 cm\"]', '[\"4mm x 5mm\"]', '[]', '[\"8mm x 5mm\"]', '[\"1.4cm\", \"0.5cm\", \"1cm\"]', '[]', '[]', '[\"1.0cm x 1.3cm\"]', '[\"1.5cm x 1cm\", \"0.5cm x 0.5cm\", \"0.8cm x 0', '[\"3mm\", \"4mm\", \"8mm\"]', '[\"0.7cm\", \"2 x 1cm\"]', '[\"1.5cm x 2cm\", \"5mm x 4mm\", \"5mm x 5mm\"]', '[]', '[\"5mm\"]', '[\"5mm\"]', '[\"0.9 x 0.8\", \"0.6 x 0.7\", \"0.5 x 0.4\"]', '[]', '[]', '[]', '[]', '[\"0.9cm\"]', '[]', '[]', '[]', '[\"1.0cm\"]', '[\"0.7 x 0.7cm\"]', '[]', '[]', '[\"0.6cm\", \"0.2cm\"]', '[\"0.4cm\"]', '[\"0.2cm\"]', '[]', '[\"0.6 x 0.7cm\"]', '[\"7mm\", \"4mm\", \"5mm\", \"5mm\", \"6mm\", \"4mm\"]', '[\"1.2 x 1 cm\"]', '[\"1cm\"]', '[]', '[\"0.5 x 1.8cm\"]', '[]', '[\"0.7cm x 0.7cm\"]', '[]', '[\"4mm\"]', '[]', '[\"4mm\"]', '[]', '[\"0.4 x 0.6cm\"]', '[]', '[]', '[]', '[\"0.1cm\", \"0.4cm\"]', '[\"7mm\"]', '[\"0.4cm\"]', '[\"0.9 x 0.8cm\"]', '[\"2.0 x 1.0 cm\"]', '[\"4mm\", \"3mm\"]', '[\"5mm\"]', '[\"0.6 x 0.6cm\", \"0.5 x 0.5cm\"]', '[]', '[\"1.2cm x 1cm\"]', '[\"5mm\"]', '[\"8mm x 10mm\", \"4mm x 5mm\", \"3mm x 4mm\", \"4mm x 5', '[]', '[]', '[\"0.5cm x 0.5cm\", \"0.5cm x 0.5cm\"]', '[]', '[\"1 cm x 1 cm\", \"2.5 cm x 1.5 cm\"]', '[\"1.1 x 1.0cm\"]', '[]', '[]', '[\"4mm x 5mm\"]', '[\"2mm\"]', '[\"0.4cm\"]', '[\"4mm\"]', '[\"1.5 x 0.9 cm\"]', '[\"0.7cm\", \"3mm\"]', '[\"1cm\", \"5mm x 6mm\", \"0.7cm\", \"1cm\"]', '[\"2mm x 3mm\"]', '[\"1cm\"]', '[]', '[\"1.2 x 1.0cm\"]', '[]', '[\"2cm x 1.4cm\", \"4cm x 2cm\", \"1cm x 1.1cm\", \"1', '[]', '[]', '[\"5mm x 6mm\"]', '[\"1cm\", \"7mm\"]', '[\"0.9 x 0.4cm\", \"0.7 x 0.4cm\", \"0.7 x 0.', '[]', '[\"0.9cm\", \"0.6cm\", \"0.7cm\"]', '[]', '[]', '[]', '[]', '[\"0.3 x 0.4cm\", \"0.6 x 0.6cm\", \"2.1 x 0.', '[\"4mm x 5mm\"]', '[]', '[]', '[]', '[]', '[]', '[\"2mm\", \"6mm\"]', '[\"1.5cm\"]', '[]', '[\"3cm x 1.5cm\"]', '[\"1.2 x 1.0 cm\"]', '[\"4mm\"]', '[\"0.5 x 0.2cm\"]', '[\"3mm\"]', '[\"1.3 x 1.3cm\", \"0.2 x 0.2cm\"]', '[\"0.8 x 0.8cm\"]', '[\"1.0cm\", \"0.8mm\", \"1.4cm\"]', '[]', '[]', '[\"5mm\", \"6mm\"]', '[]', '[\"1.1 x 0.5cm\", \"0.5 x 0.2cm\"]', '[\"0.5 x 0.4cm\"]', '[\"1cm\", \"4mm\", \"3mm\"]', '[\"1cm x 7mm\", \"6mm x 5mm\"]', '[\"6mm\"]', '[\"0.1cm x 0.1cm\"]', '[\"2.2cm x 2.2cm\", \"0.5cm x 0.4cm\"]', '[\"3cm\", \"1cm\"]', '[\"2.5cm\"]', '[\"6mm x 5mm\", \"6mm x 6mm\", \"3mm x 3mm\"]', '[\"4mm\"]', '[]', '[]', '[\"6mm x 5mm\"]', '[\"8mm x 7mm\", \"5mm x 4mm\", \"5mm x 5mm\"]', '[\"5mm x 5mm\", \"3mm\", \"3mm\"]', '[\"0.8 x 0.8 cm\"]', '[]', '[\"8mm x 5mm\", \"7mm x 5mm\"]', '[]', '[\"4mm\"]', '[\"4mm\"]', '[]', '[\"5mm\"]', '[\"5mm\"]', '[]', '[]', '[]', '[\"1cm x 2.5cm\", \"7mm x 6mm\", \"0.8mm x 0.5mm\",', '[\"1.5 x 0.9cm\", \"1.2 x 1cm\", \"2.1 x 1.5cm', '[]', '[]', '[\"1.5cm\", \"1.8cm\", \"3cm\"]', '[\"0.5cm\"]', '[\"2.0cm\", \"0.5cm\"]', '[]', '[]', '[\"0.6cm\", \"0.3cm\"]', '[\"0.4cm\", \"0.5cm\"]', '[\"0.2cm\", \"0.4cm\", \"0.3cm\", \"0.5cm\"]', '[\"0.6cm\"]', '[\"0.8cm\", \"1.0cm\", \"0.3cm\", \"0.9cm\"]', '[\"0.8cm\", \"1.0cm\", \"0.3cm\", \"0.9cm\"]', '[]', '[\"5mm\", \"6mm x 4mm\"]', '[]', '[]', '[]', '[\"0.5 x 0.5cm\"]', '[]', '[\"6mm x 4mm\"]', '[\"2 x 2mm\"]', '[\"1cm x 8mm\", \"4mm x 4mm\", \"5mm x 5mm\", \"5mm x 5', '[\"1.1cm\"]', '[\"0.9 x 1.5cm\", \"1.7cm x 1.7cm\"]', '[]', '[]', '[\"0.4 x 0.4 cm\", \"0.5 x 0.5 cm\"]', '[]', '[\"0.9 x 0.7cm\", \"2.3 x 1.1cm\"]', '[\"4mm\", \"4mm\"]', '[]', '[\"1.2cm\"]', '[\"5mm x 5mm\"]', '[\"2mm\"]', '[\"1.0 x 1.0cm\", \"0.6 x 0.6cm\", \"0.3 x 0.', '[\"1.2cm x 1.1cm\"]', '[]', '[]', '[]', '[\"0.8cm\"]', '[]', '[]', '[\"3 x 3mm\", \"4 x 5mm\", \"1.9 x 0.5cm\", \"0.3 x', '[\"5mm x 5mm\", \"5mm x 5mm\", \"5mm x 8mm\"]', '[\"1.0cm x 0.5mm\"]', '[\"0.5 x 0.5\"]', '[\"4mm x 4mm\"]', '[]', '[]', '[\"0.6 x 0.5cm\"]', '[\"0.4cm x 0.4cm\"]', '[\"0.2cm x 0.2cm\", \"1mm x 1mm\"]', '[\"1.0cm\", \"0.5cm\", \"0.5cm\"]', '[\"0.5cm\", \"0.4cm\", \"0.6cm\"]', '[\"0.3mm\"]', '[\"4mm x 4mm\", \"3mm x 3mm\"]', '[\"6mm\"]', '[\"2mm x 3mm\", \"7mm x 8mm\", \"6mm x 7mm\"]', '[]', '[]', '[\"0.9 x 0.6cm\"]', '[\"1.4 x 0.9cm\"]', '[\"4mm\", \"3mm\"]', '[]', '[]', '[\"0.3 x 0.3cm\", \"1mm\"]', '[\"0.6 x 0.6cm\", \"0.6 x 0.6cm\", \"1.2 x 1.', '[\"7mm\", \"8mm\"]', '[\"0.2cm x 0.2cm\", \"1mm x 1mm\"]', '[\"2cm x 1cm\"]', '[\"0.4cm\"]', '[\"1cm\"]', '[]', '[]', '[\"0.9 x 0.7cm\"]', '[\"0.2mm\", \"0.5cm\"]', '[\"1.4 x 0.9cm\"]', '[\"4mm x 4mm\", \"5mm x 4mm\"]', '[\"0.7cm x 1cm\"]', '[\"3mm\", \"9mm\"]', '[\"4mm x 4mm\"]', '[\"0.7cm\"]', '[\"6mm x 4mm\"]', '[\"5mm x 3mm\"]', '[\"0.5cm\"]', '[]', '[\"0.5 x 0.3cm\", \"2.2 x 2.0cm\"]', '[]', '[\"1.5cm\", \"6mm\"]', '[\"0.9cm x 0.8cm\"]', '[\"4mm\", \"5mm\"]', '[\"0.6cm x 0.4cm\"]', '[\"6mm x 4mm\"]', '[\"5.3cm x 4.2cm\", \"1.5cm x 1.6cm\", \"0.6cm x', '[\"0.4 x 0.4cm\"]', '[\"1 x 0.8cm\"]', '[\"5mm x 5mm\"]', '[]', '[\"0.5 x 0.5cm\", \"0.7 x 0.7cm\"]', '[\"1.0cm x 0.5cm\", \"0.6cm x 0.6cm\"]', '[]', '[\"4mm x 4mm\", \"4mm x 6mm\"]', '[\"1.2 x 1.3cm\"]', '[\"0.6 x 0.6 cm\"]', '[\"1.3cm x 1.2cm\", \"5mm x 3mm\", \"6mm x 3mm\"]', '[]', '[\"5mm x 5mm\", \"4mm x 4mm\", \"6mm x 5mm\", \"7mm x 5', '[\"0.3 x 0.3cm\", \"0.3 x 0.2cm\", \"0.4 x 0.']\n",
      "AP Unfiltered Array:\n",
      "['[]', '[\"0.6cm x 0.4cm\"]', '[]', '[\"3.0\"]', '[\"1cm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"5mm\"]', '[]', '[\"0.4cm\", \"1.0cm x 0.8cm\", \"0.4cm\"]', '[]', '[\"8mm\", \"1.5cm\"]', '[]', '[]', '[]', '[]', '[\"1.8cm\", \"1.0cm\"]', '[]', '[\"1cm x 1cm\"]', '[]', '[\"0.4cm\"]', '[\"5mm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"1.4cm\", \"0.5cm\"]', '[]', '[]', '[]', '[\"1-2mm\"]', '[\"4mm\", \"8mm\"]', '[]', '[]', '[]', '[]', '[\"3mm\"]', '[\"0.9 x 0.8\", \"0.6 x 0.7\", \"0.5 x 0.4\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"0.7cm\", \"0.8cm\", \"1.2cm\"]', '[]', '[\"3mm\", \"4mm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"4mm\", \"5mm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"2mm\"]', '[]', '[]', '[]', '[]', '[]', '[\"0.9cm x 0.8cm\"]', '[]', '[\"4mm\", \"3mm\"]', '[]', '[]', '[]', '[]', '[]', '[\"8mm x 10mm\", \"4mm x 5mm\", \"3mm x 4mm\", \"4mm x 5', '[\"0.4 x 0.4cm\"]', '[]', '[]', '[]', '[]', '[\"1.1 x 1 cm\"]', '[\"3mm x 4mm\"]', '[]', '[\"0.5\"]', '[]', '[]', '[\"2mm\"]', '[]', '[]', '[\"5mm x 6mm\", \"1cm\", \"1cm\", \"0.7cm\"]', '[\"3mm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"4mm\", \"3mm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"1.1cm x 1.0cm\"]', '[\"0.5cm\", \"0.7cm\", \"2.2cm\"]', '[]', '[\"8mm\"]', '[]', '[\"1.6cm\"]', '[]', '[\"0.9cm\", \"6mm\"]', '[\"4mm\"]', '[]', '[]', '[\"2mm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"2.3mm\"]', '[]', '[]', '[]', '[]', '[\"8mm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"5mm\"]', '[\"5mm\"]', '[]', '[]', '[]', '[]', '[\"1.5 x 0.9cm\", \"1.2 x 1cm\", \"2.1 x 1.5cm', '[]', '[]', '[\"1.5cm\", \"1.8cm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"8mm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"4mm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"2mm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"6mm\", \"6mm\", \"5mm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"1cm\", \"2mm\"]', '[]', '[]', '[\"1mm x 1mm\"]', '[]', '[]', '[]', '[]', '[]', '[\"2mm x 3mm\", \"7mm x 8mm\", \"6mm x 7mm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"0.3cm x 0.3cm\", \"1mm\"]', '[]', '[\"7mm\", \"8mm\"]', '[\"1mm x 1mm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"0.7cm x 1cm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"0.8 x 1.2cm\", \"0.4 x 0.4cm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"2cm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"1.9mm\", \"0.4mm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]']\n",
      "A Unfiltered Array:\n",
      "['[\"0.8 x 0.8 cm\", \"0.4 x 0.5 cm\"]', '[\"0.7 x 0.7cm\"]', '[]', '[]', '[]', '[]', '[]', '[\"0.9cm x 0.9cm\", \"0.9cm x 0.6cm\", \"0.6cm x', '[]', '[\"0.9 x 0.7cm\"]', '[]', '[\"0.7cm x 1.3cm\"]', '[]', '[]', '[\"7mm\", \"0.5 x 0.4cm\"]', '[]', '[]', '[]', '[\"0.8cm x 0.7cm\"]', '[]', '[\"0.4cm x 0.4cm\", \"0.5cm x 0.3cm\"]', '[\"0.5 x 0.4cm\"]', '[\"0.8cm x 0.6cm\", \"1.0cm x 1.0cm\", \"0.8cm x', '[]', '[\"0.9 x 0.6cm\", \"0.7 x 0.5cm\"]', '[]', '[\"0.6cm x 0.5cm\"]', '[]', '[\"0.6cm x 0.5cm\"]', '[\"1.8cm\", \"1.0cm\"]', '[\"0.8cm x 0.5cm\", \"0.5cm x 0.4cm\"]', '[\"1.1 x 0.7cm\", \"0.9 x 0.6cm\", \"1 x 1.5cm', '[\"7mm x 5mm\", \"6mm x 5mm\"]', '[\"0.4 x 0.3cm\"]', '[\"0.3cm x 0.4cm\"]', '[\"0.3cm x 0.2cm\", \"2mm\"]', '[]', '[]', '[\"0.9 x 0.7cm\", \"0.7 x 0.6cm\", \"0.5 x 0.', '[\"1.3cm x 0.9cm\", \"1.0cm x 1.0cm\"]', '[]', '[]', '[\"0.5cm x 0.4cm\", \"0.7cm x 0.5cm\"]', '[\"8mm x 5mm\"]', '[\"1.4cm\", \"0.5cm\"]', '[\"0.7cm x 0.6cm\"]', '[\"0.8cm x 0.6cm\", \"0.9cm x 0.8cm\", \"0.8cm x', '[\"1.5cm x 1.2cm\"]', '[]', '[]', '[]', '[]', '[\"0.5cm x 0.4cm\", \"0.4cm x 0.4cm\"]', '[\"5mm\", \"0.9 x 0.6cm\"]', '[]', '[\"0.7cm x 0.6cm\", \"0.6cm x 0.5cm\", \"0.3cm x', '[\"0.5 x 0.4cm\", \"0.4 x 0.3cm\", \"0.6 x 0.', '[\"1.3cm x 1.1cm\"]', '[]', '[\"0.9 x 0.8cm\"]', '[\"0.9cm\"]', '[\"0.7 x 0.5cm\"]', '[\"1.3 x 0.7cm\", \"1.6 x 1.3cm\", \"1.7 x 1.', '[\"0.7cm x 0.6cm\", \"1.4cm x 1.2cm\"]', '[\"1.1cm x 0.7cm\"]', '[]', '[\"0.6 x 0.6cm\", \"0.7 x 0.5cm\", \"0.6 x 0.', '[\"1.2 x 0.6cm\", \"0.9 x 0.5cm\", \"0.8 x 0.', '[\"0.8cm x 0.4cm\", \"0.2cm x 0.2cm\", \"0.3cm x', '[\"0.3cm x 0.2cm\"]', '[]', '[\"1.0 x 0.8cm\"]', '[]', '[\"1.1cm x 0.7cm\", \"0.5cm x 0.4cm\", \"1cm x 0', '[]', '[\"0.4cm x 0.3cm\", \"1.1 x 0.4cm\", \"0.3cm x', '[]', '[]', '[\"0.7cm x 0.6cm\", \"0.6cm x 0.5cm\"]', '[\"0.8cm x 0.5cm\"]', '[\"0.7 x 0.5cm\"]', '[\"0.8 x 0.6cm\"]', '[\"0.7 x 0.5cm\", \"0.6 x 0.5cm\"]', '[\"0.3cm x 0.2cm\"]', '[\"0.9 x 0.8cm\", \"1.0 x 0.7cm\", \"0.9 x 0.', '[]', '[\"0.7 x 0.6cm\", \"0.2cm x 0.4cm\"]', '[\"0.5 x 0.4cm\"]', '[\"0.3cm x 0.2cm\"]', '[\"0.5cm x 0.4cm\", \"0.6cm x 0.5cm\"]', '[\"0.6cm x 0.5cm\"]', '[\"1.3mm\"]', '[\"0.9 x 0.5cm\", \"0.5 x 0.5cm\"]', '[\"1.4 x 0.9cm\"]', '[\"4mm\", \"3mm\"]', '[\"0.6 x 0.4cm\", \"0.8 x 0.6cm\"]', '[\"0.3cm x 0.4cm\", \"0.5cm x 0.3cm\"]', '[]', '[\"0.9 x 0.7cm\"]', '[\"0.6 x 0.6cm\"]', '[\"8mm x 10mm\", \"4mm x 5mm\", \"3mm x 4mm\"]', '[\"0.6 x 0.5cm\", \"0.7 x 0.5cm\"]', '[\"1.3cm x 1.0cm\", \"0.6cm x 0.6cm\"]', '[\"0.5cm x 0.4cm\", \"0.4cm x 0.3cm\"]', '[\"0.8 x 0.5cm\", \"0.7 x 0.6cm\"]', '[\"1.2cm x 1.0cm\", \"2.3cm x 2.0cm\"]', '[\"0.9 x 0.7cm\", \"0.8 x 0.7cm\"]', '[\"3mm x 4mm\", \"0.6mm\"]', '[\"0.5 x 0.3cm\", \"0.6 x 0.4cm\"]', '[\"0.5 x 0.4cm\"]', '[\"1.0cm x 0.4cm\", \"1.0cm x 1.0cm\", \"0.9cm x', '[]', '[\"4mm\", \"0.3cm x 0.2cm\"]', '[\"1.5 x 0.9 cm\"]', '[\"0.7cm\"]', '[\"6mm\", \"1cm\", \"1cm\", \"0.7cm\"]', '[\"3mm\", \"0.5cm x 0.4cm\"]', '[\"0.8cm x 0.4cm\"]', '[\"0.9cm x 0.7cm\"]', '[\"0.9 x 0.6cm\", \"0.7 x 0.7cm\"]', '[\"1.2cm x 1.0cm\"]', '[]', '[\"0.7 x 0.7cm\", \"0.8 x 0.6cm\", \"1.0 x 0.', '[\"0.9 x 0.7cm\", \"0.7 x 0.7cm\"]', '[\"5mm x 6mm\", \"0.9 x 0.7cm\"]', '[\"0.4cm x 0.3cm\", \"0.4cm x 0.2cm\"]', '[]', '[\"0.3cm x 0.2cm\", \"0.6cm x 0.4cm\"]', '[]', '[\"0.5cm x 0.4cm\"]', '[\"0.6cm x 0.4cm\"]', '[\"1.4 x 1cm\", \"0.8 x 0.5cm\", \"0.3cm\", \"0.6', '[\"1.1cm x 1.0cm\", \"0.6 x 0.4cm\"]', '[\"0.4 x 0.3cm\", \"0.8 x 0.7cm\", \"1.0 x 0.', '[\"0.8 x 0.7cm\"]', '[\"8mm\", \"0.9cm x 0.5cm\"]', '[\"0.5 x 0.4cm\"]', '[]', '[\"0.8cm x 0.6cm\"]', '[\"0.7cm x 0.5cm\", \"0.5cm x 0.5cm\", \"0.7cm x', '[\"0.4cm x 0.3cm\", \"0.3cm x 0.3cm\"]', '[\"0.5 x 0.4cm\"]', '[\"0.9 x 0.7cm\", \"1 x 0.7cm\", \"0.9 x 0.7cm', '[\"0.2cm x 0.2cm\", \"0.2cm x 0.2cm\"]', '[\"1 x 0.7cm\"]', '[\"0.5cm x 0.4cm\", \"0.7cm x 0.5cm\"]', '[]', '[\"0.9 x 0.5cm\"]', '[]', '[\"0.9cm x 0.4cm\"]', '[\"1.0cm\", \"0.8mm\", \"1.4cm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[\"2cm\"]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', '[]']\n"
     ]
    }
   ],
   "source": [
    "# For testing which voting method works best\n",
    "# Clean output\n",
    "def cleanResponse(line):\n",
    "    clean_output = [word.lower().strip(string.punctuation) for word in line.split() if word.lower().strip(string.punctuation) in ['yes', 'no']]\n",
    "    if \"yes\" in clean_output:\n",
    "        return \"y\"\n",
    "    elif \"no\" in clean_output:\n",
    "        return \"n\"\n",
    "    else:\n",
    "        return \"error\"\n",
    "\n",
    "def checkLine(string, line, array): # Cleans response an adds to appropriate array\n",
    "    if string in line:\n",
    "        clean_output = cleanResponse(line)\n",
    "        array.append(clean_output)\n",
    "        \n",
    "def checkLineSize(string, line, array): # Cleans response an adds to appropriate array (only for Size question)\n",
    "    if string in line:\n",
    "        clean_output = line.split(\":\", 1)[1].strip() # Extract the part after the patint note column label\n",
    "        array.append(clean_output)\n",
    "\n",
    "def getIndex(string, line):\n",
    "    if string in line:\n",
    "        index = re.findall(r'\\d+', line)\n",
    "        return int(index[0])\n",
    "    return None\n",
    "\n",
    "with open(txt_string, \"r\") as log_file:\n",
    "    file_content = log_file.readlines() # Read all lines, turn them into strings\n",
    "\n",
    "PE_unfiltered_array = []\n",
    "AP_unfiltered_array = []\n",
    "A_unfiltered_array = []\n",
    "true_results = [0 for i in range(sample_size)]\n",
    "index = 0\n",
    "\n",
    "# For all other questions\n",
    "def getData():\n",
    "    for line in file_content:\n",
    "        checkLine(\"PE Unfiltered\", line, PE_unfiltered_array) # Fill in arrays with GPT responses from txt file\n",
    "        checkLine(\"A&P Unfiltered\", line, AP_unfiltered_array)\n",
    "        checkLine(\"A Unfiltered\", line, A_unfiltered_array)\n",
    "        index = getIndex(\"Index\", line)\n",
    "\n",
    "        if index is not None:\n",
    "            true_results[index] = Cat.at[index, ground_truth_string] # Get the ground truth for current index\n",
    "            if pd.isna(true_results[index]):\n",
    "                true_results[index] = \"NaN error\"\n",
    "                #print(f\"NaN at index {index}\")\n",
    "\n",
    "            elif isinstance(true_results[index], str):\n",
    "                raw = true_results[index]\n",
    "                parts = [p.lower().strip() for p in raw.split('/')]\n",
    "                if any('y' in p for p in parts):  # This matches \"y\", \"yes\", \"y/n\", etc.\n",
    "                    true_results[index] = \"y\"\n",
    "                else:\n",
    "                    true_results[index] = \"n\"\n",
    "\n",
    "# Only for Size question\n",
    "def getDataSize():\n",
    "    for line in file_content:\n",
    "        checkLineSize(\"PE Unfiltered\", line, PE_unfiltered_array) # Fill in arrays with GPT responses from txt file\n",
    "        checkLineSize(\"A&P Unfiltered\", line, AP_unfiltered_array)\n",
    "        checkLineSize(\"A Unfiltered\", line, A_unfiltered_array)\n",
    "        index = getIndex(\"Index\", line)\n",
    "\n",
    "        if index is not None:\n",
    "            true_results[index] = Cat.at[index, ground_truth_string] # Get the ground truth for current index\n",
    "            if pd.isna(true_results[index]):\n",
    "                true_results[index] = -1 # No valid tumor size provided in Ground Truth\n",
    "                #print(f\"NaN at index {index}\")\n",
    "\n",
    "            if isinstance(true_results[index], (str, float)):\n",
    "                result_str = str(true_results[index]).strip() # Convert to string to strip whitespaces and process\n",
    "                \n",
    "                if result_str:\n",
    "                    sizes_real_parts = re.split(r'[;/]', result_str)\n",
    "                    valid_sizes = []\n",
    "\n",
    "                    for part in sizes_real_parts:\n",
    "                        part = part.strip()\n",
    "                        if re.search(r'NA|nan', part, re.IGNORECASE):\n",
    "                            continue\n",
    "                        if re.match(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', part):\n",
    "                            continue\n",
    "                        num_match = re.search(r'(\\d*\\.?\\d+)', part)\n",
    "                        if num_match:\n",
    "                            valid_sizes.append(float(num_match.group(1)))\n",
    "\n",
    "                    largest_size_real = max(valid_sizes) if valid_sizes else -1\n",
    "\n",
    "                else:\n",
    "                    largest_size_real = -1 # No valid tumor size provided in Ground Truth\n",
    "            else:\n",
    "                largest_size_real = -1 # No valid tumor size provided in Ground Truth\n",
    "            \n",
    "            true_results[index] = largest_size_real  # Store largest size in true_results\n",
    "\n",
    "#getData()\n",
    "getDataSize()\n",
    "\n",
    "num_y = true_results.count(\"y\")\n",
    "num_n = true_results.count(\"n\")\n",
    "num_nan = true_results.count(-1)\n",
    "print(f\"# of 'Y' in Ground Truth: {num_y}\")\n",
    "print(f\"# of 'N' in Ground Truth: {num_n}\")\n",
    "print(f\"# of NaN values in Ground Truth: {num_nan}\")\n",
    "\n",
    "print(f\"Ground Truth:\\n{true_results}\")\n",
    "print(f\"PE Unfiltered Array:\\n{PE_unfiltered_array}\")\n",
    "print(f\"AP Unfiltered Array:\\n{AP_unfiltered_array}\")\n",
    "print(f\"A Unfiltered Array:\\n{A_unfiltered_array}\")\n",
    "# 24 113 281 NaN\n",
    "# 36 62 67 75 115 126 131 186 189 197 199 207 222 228 239 241 242 243 254 279 286 287 288 Y/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fedb767d-f1b9-49de-af63-c10a89696046",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "[0.8, 0.6, 0.3, 6.5, 1.6, 0.4, 0.3, -2, -2, 1.5, 1.2, -2, -2, 0.3, 0.7, 0.5, 0.4, 0.4, 1.0, 0.5, 0.8, 0.4, -2, -2, 1.5, 1.1, 0.4, 1.7, 0.5, 1.8, -2, 1.0, -2, -2, -2, 0.2, -2, 0.8, -2, -2, 0.9, 0.5, -2, 0.8, 1.4, -2, -2, 1.3, 1.5, -2, -2, 2.0, -2, 0.5, 0.5, -2, -2, -2, -2, -2, 0.9, -2, -2, -2, 1.0, 0.7, -2, -2, 0.6, 0.4, 0.2, -2, 0.7, -2, 1.2, 1.0, -2, 1.8, -2, 0.7, -2, 0.4, -2, 0.4, -2, 0.6, -2, -2, -2, -2, 0.7, 0.4, 0.9, 2.0, 0.4, 0.5, 0.6, -2, 1.2, 0.5, 5.0, -2, -2, 0.5, -2, 2.5, 1.1, -2, -2, 0.5, -2, 0.4, 0.4, 1.5, 0.7, 1.0, 0.3, 1.0, -2, 1.2, -2, -2, -2, -2, 0.6, 1.0, 0.9, -2, 0.9, -2, -2, -2, -2, -2, 0.5, -2, -2, -2, -2, -2, -2, 1.5, -2, 3.0, 1.2, 0.4, 0.5, 0.3, 1.3, 0.8, -2, -2, -2, 0.6, -2, -2, 0.5, -2, 1.0, 0.6, 0.1, 2.2, 3.0, 2.5, -2, 0.4, -2, -2, 0.6, 0.8, -2, 0.8, -2, 0.8, -2, 0.4, 0.4, -2, 0.5, 0.5, -2, -2, -2, 2.5, -2, -2, -2, -2, 0.5, 2.0, -2, -2, 0.6, -2, 0.5, 0.6, 1.0, 1.0, -2, 0.6, -2, -2, -2, 0.5, -2, 0.6, -2, 5.0, 1.1, 1.7, -2, -2, 0.5, -2, -2, 0.4, -2, 1.2, 0.5, 0.2, 1.0, 1.2, -2, -2, -2, 0.8, -2, -2, -2, -2, 1.0, 0.5, 0.4, -2, -2, 0.6, 0.4, 0.2, 1.0, 0.6, 0.03, 0.4, 0.6, 0.8, -2, -2, 0.9, 1.4, 0.4, -2, -2, 0.3, -2, 0.8, 0.2, 2.0, 0.4, 1.0, -2, -2, 0.9, -2, 1.4, 0.5, 1.0, -2, 0.4, 0.7, 0.6, 0.5, 0.5, -2, 2.2, -2, 1.5, 0.9, 0.5, 0.6, 0.6, -2, 0.4, 1.0, 0.5, -2, 0.7, 1.0, -2, -2, 1.3, 0.6, 1.3, -2, -2, -2]\n",
      "[-2, 0.6, -2, 3.0, 1.0, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, 0.5, -2, -2, -2, 1.5, -2, -2, -2, -2, 1.8, -2, 1.0, -2, 0.4, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, 1.4, -2, -2, -2, 1.0, -2, -2, -2, -2, -2, 0.3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, 0.4, -2, -2, -2, -2, -2, -2, 0.5, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, 0.2, -2, -2, -2, -2, -2, 0.9, -2, 0.4, -2, -2, -2, -2, -2, 5.0, -2, -2, -2, -2, -2, 1.1, -2, -2, 0.5, -2, -2, 0.2, -2, -2, 1.0, 0.3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, 1.1, -2, -2, -2, -2, -2, -2, 0.9, -2, -2, -2, 0.2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, 0.23, -2, -2, -2, -2, 0.8, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, 0.5, 0.5, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, 0.2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, 0.1, -2, -2, -2, -2, -2, 0.8, -2, -2, -2, -2, -2, -2, -2, 0.3, -2, 0.8, 0.1, -2, -2, -2, -2, -2, -2, -2, -2, -2, 1.0, -2, -2, -2, -2, -2, -2, 1.2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, 0.19, -2, -2, -2, -2, -2, -2, -2]\n",
      "[0.8, 0.7, -2, -2, -2, -2, -2, -2, -2, 0.9, -2, 1.3, -2, -2, 0.7, -2, -2, -2, 0.8, -2, 0.5, 0.5, -2, -2, 0.9, -2, 0.6, -2, 0.6, 1.8, 0.8, 1.5, -2, 0.4, -2, 0.3, -2, -2, -2, -2, -2, -2, 0.7, 0.8, 1.4, 0.7, 0.9, 1.5, -2, -2, -2, -2, -2, 0.9, -2, -2, 0.6, 1.3, -2, 0.9, 0.9, 0.7, -2, 1.4, 1.1, -2, -2, 1.2, 0.8, 0.3, -2, 1.0, -2, -2, -2, 1.1, -2, -2, 0.7, 0.8, -2, 0.8, 0.7, 0.3, 1.0, -2, 0.7, 0.5, -2, -2, 0.6, 0.13, 0.9, 1.4, 0.4, 0.8, 0.5, -2, 0.9, 0.6, 1.0, -2, -2, 0.5, 0.8, 2.3, 0.9, -2, 0.6, 0.5, -2, -2, 0.4, 1.5, 0.7, 1.0, 0.5, 0.8, 0.9, 0.9, 1.2, -2, 1.0, -2, 0.9, 0.4, -2, 0.6, -2, 0.5, 0.6, -2, 1.1, -2, 0.8, -2, -2, -2, 0.8, 0.7, -2, 0.5, 1.0, 0.2, 1.0, 0.7, -2, 0.9, -2, 0.9, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, 2.0, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n"
     ]
    }
   ],
   "source": [
    "# Check if 2 arrays are the same output, if so return one of them if it is not empty, bias towards A\n",
    "def majorityVoteCheck(index):\n",
    "    A_val = A_unfiltered_array[index]\n",
    "    PE_val = PE_unfiltered_array[index]\n",
    "    AP_val = AP_unfiltered_array[index]\n",
    "    \n",
    "    if A_val == PE_val or A_val == AP_unfiltered_array[index]: # If A or either match\n",
    "        if A_val: return A_val\n",
    "        elif PE_val: return PE_val\n",
    "        elif AP_val: return AP_val\n",
    "    elif PE_val == AP_val: # If A&P and A match\n",
    "        if PE_val: return PE_val\n",
    "        elif AP_val: return AP_val\n",
    "    else: # None match, return A\n",
    "        return A_val\n",
    "            \n",
    "# Only call other 2 columns to check for false positives (0=PE 1=A&P 2=A)\n",
    "def prioritizeColumn(index, prioritize_column_index):\n",
    "    col_arrays = [PE_unfiltered_array, AP_unfiltered_array, A_unfiltered_array]\n",
    "    col_prioritize = col_arrays[prioritize_column_index]\n",
    "    \n",
    "    if \"y\" in col_prioritize[index]:\n",
    "        # This is where other 2 are called by GPT in other file\n",
    "        other_indices = [i for i in [0, 1, 2] if i != prioritize_column_index]\n",
    "        for i in other_indices:\n",
    "            if \"y\" in col_arrays[i][index]:\n",
    "                return \"y\"\n",
    "        return \"n\"  # Prioritized Column said Yes, but others disagreed, possible false positive\n",
    "    else:\n",
    "        return \"n\"\n",
    "    \n",
    "import re\n",
    "\n",
    "# Convert mm to cm if needed and round to 2 decimal places.\n",
    "def convert_size(val, unit):\n",
    "    if unit:\n",
    "        unit = unit.lower()\n",
    "        if unit in ['mm', 'millimeters']:\n",
    "            val /= 10\n",
    "    return round(val, 2)\n",
    "\n",
    "# Extract  sizes, covers multiple input types\n",
    "def extract_numeric_sizes(size_string):\n",
    "    size_matches = re.findall(\n",
    "        r'(\\d*\\.?\\d+)\\s*to\\s*(\\d*\\.?\\d+)?\\s*(cm|mm|millimeters)?'                             # e.g. \"8 to 10 mm\"\n",
    "        r'|(\\d*\\.?\\d+)\\s*(cm|mm|millimeters)?\\s*[x×]?\\s*(\\d*\\.?\\d+)?\\s*(cm|mm|millimeters)?'  # e.g. \"4 x 5 mm\"\n",
    "        r'|(\\d*\\.?\\d+)\\s*-\\s*(\\d*\\.?\\d+)\\s*(cm|mm|millimeters)?',                             # e.g. \"2-3 mm\"\n",
    "        size_string,\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    numeric_sizes = []\n",
    "\n",
    "    for match in size_matches:\n",
    "        # Case 1: \"X to Y unit\"\n",
    "        if match[0]:\n",
    "            val1 = convert_size(float(match[0]), match[2])\n",
    "            val2 = convert_size(float(match[1]), match[2]) if match[1] else val1\n",
    "            numeric_sizes.append(max(val1, val2))\n",
    "\n",
    "        # Case 2: \"X x Y unit\"\n",
    "        elif match[3]:\n",
    "            val1 = convert_size(float(match[3]), match[4])\n",
    "            val2 = convert_size(float(match[5]), match[6]) if match[5] else val1\n",
    "            numeric_sizes.append(max(val1, val2))\n",
    "\n",
    "        # Case 3: \"X - Y unit\"\n",
    "        elif match[7]:\n",
    "            val1 = convert_size(float(match[7]), match[9])\n",
    "            val2 = convert_size(float(match[8]), match[9])\n",
    "            numeric_sizes.append(max(val1, val2))\n",
    "\n",
    "    return numeric_sizes\n",
    "\n",
    "# Processes GPT responses and returns a final largest size in cm\n",
    "def evaluate_size_responses(output, true_results, sample_size, skip_patients, skip_patients_array):\n",
    "    output_final = [-2 for i in range(len(output))] # Default to -2 (invalid GPT response)\n",
    "    mmArr = [0 for i in range(len(output))]\n",
    "\n",
    "    for i in range(min(sample_size, len(output))):\n",
    "        if skip_patients and i in skip_patients_array:\n",
    "            continue\n",
    "\n",
    "        response = output[i]\n",
    "        if not isinstance(response, str) or response.strip().lower() in [\"na\", \"n/a\", \"\"]:\n",
    "            continue\n",
    "\n",
    "        numeric_sizes = extract_numeric_sizes(response)\n",
    "\n",
    "        if not numeric_sizes:\n",
    "            output_final[i] = -2  # Invalid GPT response\n",
    "            continue\n",
    "\n",
    "        max_size = max(numeric_sizes)\n",
    "        output_final[i] = round(max_size, 2)\n",
    "\n",
    "    return output_final\n",
    "\n",
    "only_PE = [0 for i in range(sample_size)]\n",
    "only_AP = [0 for i in range(sample_size)]\n",
    "only_A = [0 for i in range(sample_size)]\n",
    "majority_vote = [0 for i in range(sample_size)]\n",
    "prioritize_PE = [0 for i in range(sample_size)]\n",
    "prioritize_AP = [0 for i in range(sample_size)]\n",
    "prioritize_A = [0 for i in range(sample_size)]\n",
    "\n",
    "for i in range(0, sample_size): # This is where all the types of votes are run\n",
    "    #only_PE[i] = PE_unfiltered_array[i]\n",
    "    #only_AP[i] = AP_unfiltered_array[i]\n",
    "    only_A[i] = A_unfiltered_array[i]\n",
    "    if len(PE_unfiltered_array) > 0 and len(AP_unfiltered_array) > 0 and len(A_unfiltered_array) > 0:\n",
    "        majority_vote[i] = majorityVoteCheck(i)\n",
    "        prioritize_PE[i] = prioritizeColumn(i, 0)\n",
    "        prioritize_AP[i] = prioritizeColumn(i, 1)\n",
    "        prioritize_A[i] = prioritizeColumn(i, 2)\n",
    "    else:\n",
    "        only_A_flag = True\n",
    "\n",
    "# For size question only, change to be called better later\n",
    "output_final_PE = evaluate_size_responses(PE_unfiltered_array, true_results, sample_size, skip_patients, skip_patients_array)\n",
    "output_final_AP = evaluate_size_responses(AP_unfiltered_array, true_results, sample_size, skip_patients, skip_patients_array)\n",
    "output_final_A = evaluate_size_responses(A_unfiltered_array, true_results, sample_size, skip_patients, skip_patients_array)\n",
    "        \n",
    "print(\"Done\")\n",
    "#print(majority_vote)\n",
    "#print(prioritize_column)\n",
    "print(output_final_PE)\n",
    "print(output_final_AP)\n",
    "print(output_final_A)\n",
    "# prioritize_column -> prioritize_PE, prioritize_AP, prioritize_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28d1a51a-cfd7-46cf-ac58-a3fb55a7463b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.96%\n"
     ]
    }
   ],
   "source": [
    "def confusionMatrix(vote_array):\n",
    "    TP = TN = FP = FN = 0\n",
    "    for i in range(0, min((sample_size), len(Cat))):\n",
    "        if vote_array[i] == true_results[i]: # True+/True-\n",
    "            if vote_array[i] == \"y\": # True Positive\n",
    "                TP += 1\n",
    "            elif vote_array[i] == \"n\": # True Negative\n",
    "                TN += 1\n",
    "        elif(vote_array[i] != true_results[i] and true_results[i] != \"NaN error\" and vote_array[i] != \"error\"): # False+/False-\n",
    "            if vote_array[i] == \"y\": # False Positive\n",
    "                FP += 1\n",
    "            elif vote_array[i] == \"n\": # False Negative\n",
    "                FN += 1\n",
    "    return {\"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN}\n",
    "\n",
    "def confusionMetrics(confusion_matrix):\n",
    "    TP = confusion_matrix[\"TP\"]\n",
    "    TN = confusion_matrix[\"TN\"]\n",
    "    FP = confusion_matrix[\"FP\"]\n",
    "    FN = confusion_matrix[\"FN\"]\n",
    "    \n",
    "    total = TP + TN + FP + FN\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN) if total else 0 # How often did model predict correctly\n",
    "    precision = TP / (TP + FP) if (TP + FP) else 0 # When model predicted Y, how often was it correct\n",
    "    recall = TP / (TP + FN) if (TP + FN) else 0 # How many of the true Y cases did model correctly identify\n",
    "    F1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0 # Balance between Precision and Recall\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"F1\": F1}\n",
    "\n",
    "def formatConfusionMatrix(matrix, metrics, label):     \n",
    "    output = [f\"\\nConfusion Matrix {label}:\"]\n",
    "    for name, value in matrix.items():\n",
    "        output.append(f\"{name}: {value}\")\n",
    "    output.append(f\"\\nConfusion Matrix Metrics {label}:\")\n",
    "    for name, value in metrics.items():\n",
    "        output.append(f\"{name}: {(value * 100):.2f}\")\n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "def evaluate_size_accuracy(predictions, true_results):\n",
    "    correct = 0\n",
    "    total = len(predictions)\n",
    "    \n",
    "    for i in range(total):\n",
    "        if predictions[i] == true_results[i]:  # If the predicted size matches the true result\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy = (correct / total) * 100 if total else 0  # Percentage of correct predictions\n",
    "    return accuracy\n",
    "\n",
    "def generateMatrices():\n",
    "    with open(\"matrices/ae_matrix(3).txt\", \"a\") as log_file:\n",
    "        if only_A_flag == False:\n",
    "            confusion_matrix_PE = confusionMatrix(only_PE)\n",
    "            confusion_metrics_PE = confusionMetrics(confusion_matrix_PE)\n",
    "            output_PE = formatConfusionMatrix(confusion_matrix_PE, confusion_metrics_PE, \"PE\")\n",
    "            print(output_PE)\n",
    "            log_file.write(output_PE + \"\\n\")\n",
    "\n",
    "            confusion_matrix_AP = confusionMatrix(only_AP)\n",
    "            confusion_metrics_AP = confusionMetrics(confusion_matrix_AP)\n",
    "            output_AP= formatConfusionMatrix(confusion_matrix_AP, confusion_metrics_AP, \"A&P\")\n",
    "            print(output_AP)\n",
    "            log_file.write(output_AP + \"\\n\")\n",
    "\n",
    "        confusion_matrix_A = confusionMatrix(only_A)\n",
    "        confusion_metrics_A = confusionMetrics(confusion_matrix_A)\n",
    "        output_A = formatConfusionMatrix(confusion_matrix_A, confusion_metrics_A, \"Addendum\")\n",
    "        print(output_A)\n",
    "        log_file.write(output_A + \"\\n\")\n",
    "\n",
    "        if only_A_flag == False:\n",
    "            confusion_matrix_majority = confusionMatrix(majority_vote)\n",
    "            confusion_metrics_majority = confusionMetrics(confusion_matrix_majority)\n",
    "            output_majority = formatConfusionMatrix(confusion_matrix_majority, confusion_metrics_majority, \"Majority\")\n",
    "            print(output_majority)\n",
    "            log_file.write(output_majority + \"\\n\")\n",
    "\n",
    "            prioritize_outputs = {\n",
    "                \"Prioritize PE\": prioritize_PE,\n",
    "                \"Prioritize AP\": prioritize_AP,\n",
    "                \"Prioritize A\": prioritize_A\n",
    "            }\n",
    "\n",
    "            for name, results in prioritize_outputs.items():\n",
    "                cm = confusionMatrix(results)\n",
    "                metrics = confusionMetrics(cm)\n",
    "                output = formatConfusionMatrix(cm, metrics, name)\n",
    "                print(output)\n",
    "                log_file.write(output + \"\\n\")\n",
    "                \n",
    "#generateMatrices()\n",
    "accuracy = evaluate_size_accuracy(output_final_PE, true_results)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "# Accuracy: 48.98% no skips\n",
    "# Accuracy: 47.96% with skips, clearly I implemented something in here wrong lol, either regex or comparisons were done wrong\n",
    "# Just test in open_ai_nicky.ipynb for Size cause there's no time to fix this\n",
    "# Running in open_ai_nicky.ipynb gave Accuracy = 98.18% so yeah something was done incorrectly here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa25d4-8026-49ac-8bd8-bfee730e11d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDAS Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
